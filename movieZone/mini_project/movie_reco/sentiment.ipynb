{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66621fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only sentiment analysis and accurscy is measured in this notebook sentiment is not predicted\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from bs4 import BeautifulSoup\n",
    "import re,string,unicodedata\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.stem import LancasterStemmer,WordNetLemmatizer\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from textblob import TextBlob\n",
    "from textblob import Word\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4bed756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>If you like original gut wrenching laughter yo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "5  Probably my all-time favorite movie, a story o...  positive\n",
       "6  I sure would like to see a resurrection of a u...  positive\n",
       "7  This show was an amazing, fresh & innovative i...  negative\n",
       "8  Encouraged by the positive comments about this...  negative\n",
       "9  If you like original gut wrenching laughter yo...  positive"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_data=pd.read_csv('tmdb_reviews.csv')\n",
    "print(imdb_data.shape)\n",
    "imdb_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "268e8a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_data = imdb_data.head(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca7c9adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>9983</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Beautiful film, pure Cassavetes style. Gena Ro...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2</td>\n",
       "      <td>5028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   review sentiment\n",
       "count                                               10000     10000\n",
       "unique                                               9983         2\n",
       "top     Beautiful film, pure Cassavetes style. Gena Ro...  positive\n",
       "freq                                                    2      5028"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56cf9bdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    5028\n",
       "negative    4972\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_data['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "913a0a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000,) (4000,)\n",
      "(6000,) (6000,)\n"
     ]
    }
   ],
   "source": [
    "train_reviews=imdb_data.review[:4000]\n",
    "train_sentiments=imdb_data.sentiment[:4000]\n",
    "#test dataset\n",
    "test_reviews=imdb_data.review[4000:]\n",
    "test_sentiments=imdb_data.sentiment[4000:]\n",
    "print(train_reviews.shape,train_sentiments.shape)\n",
    "print(test_reviews.shape,test_sentiments.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8597f516",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=ToktokTokenizer()\n",
    "#Setting English stopwords\n",
    "stopword_list=nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7bc80510",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sahithi\\appdata\\local\\programs\\python\\python39-32\\lib\\site-packages\\bs4\\__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def strip_html(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "#Removing the square brackets\n",
    "def remove_between_square_brackets(text):\n",
    "    return re.sub('\\[[^]]*\\]', '', text)\n",
    "\n",
    "#Removing the noisy text\n",
    "def denoise_text(text):\n",
    "    text = strip_html(text)\n",
    "    text = remove_between_square_brackets(text)\n",
    "    return text\n",
    "#Apply function on review column\n",
    "imdb_data['review']=imdb_data['review'].apply(denoise_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a92a0e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special_characters(text, remove_digits=True):\n",
    "    pattern=r'[^a-zA-z0-9\\s]'\n",
    "    text=re.sub(pattern,'',text)\n",
    "    return text\n",
    "#Apply function on review column\n",
    "imdb_data['review']=imdb_data['review'].apply(remove_special_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d32ebe75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemming the text\n",
    "def simple_stemmer(text):\n",
    "    ps=nltk.porter.PorterStemmer()\n",
    "    text= ' '.join([ps.stem(word) for word in text.split()])\n",
    "    return text\n",
    "#Apply function on review column\n",
    "imdb_data['review']=imdb_data['review'].apply(simple_stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "053a1938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'had', 'over', 'were', 've', 'in', 'won', 'a', 'each', 'she', 'all', \"you'll\", 'more', 'during', 'myself', 'why', 'who', 'these', \"wouldn't\", 'then', 'how', \"aren't\", 'shouldn', 'haven', 'i', 'been', \"she's\", \"you're\", 'him', 'yours', 'very', 'couldn', 'its', 'should', \"you'd\", 'your', \"doesn't\", 'just', 'at', 'out', 'and', 'her', 'by', 'hers', \"you've\", 'this', \"mightn't\", 'did', 'as', 'doing', 'off', 'my', 'so', 'themselves', 'isn', 'it', 'being', \"it's\", 'be', 'once', 'not', 'below', 'y', \"mustn't\", 'both', 'between', \"that'll\", 'when', 'didn', 'm', 'can', 'them', \"weren't\", 'nor', 're', 'from', 'ain', 'or', 'after', 'for', 'same', \"shan't\", 'while', 'd', \"won't\", 'doesn', 'has', 'again', \"wasn't\", 'with', 'we', 'their', 'own', \"hadn't\", 'aren', 'needn', 'into', 'hadn', 'he', 'what', 'there', 'against', 'to', 'mightn', 'up', 'wouldn', 'o', 'his', 'further', 'than', 'ourselves', 's', 'where', 'such', 'don', \"haven't\", 'you', 'is', \"didn't\", 'until', 'an', 'about', 'yourself', 'shan', 'on', 'under', 'theirs', 'himself', 'mustn', \"don't\", 'through', 'of', 'll', 'other', \"should've\", \"hasn't\", 'ours', \"needn't\", 't', 'whom', 'here', 'our', 'that', 'yourselves', 'having', 'which', 'some', 'herself', 'because', 'if', 'no', 'am', 'me', 'hasn', 'most', 'itself', 'do', \"isn't\", 'now', 'weren', 'those', 'are', 'wasn', 'but', 'the', 'few', 'down', 'does', 'was', 'any', 'before', 'above', 'will', \"couldn't\", 'too', 'ma', 'only', \"shouldn't\", 'they', 'have'}\n"
     ]
    }
   ],
   "source": [
    "stop=set(stopwords.words('english'))\n",
    "print(stop)\n",
    "\n",
    "#removing the stopwords\n",
    "def remove_stopwords(text, is_lower_case=False):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    if is_lower_case:\n",
    "        filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
    "    else:\n",
    "        filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
    "    filtered_text = ' '.join(filtered_tokens)    \n",
    "    return filtered_text\n",
    "#Apply function on review column\n",
    "imdb_data['review']=imdb_data['review'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "325f554b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'one review ha mention watch 1 oz episod youll hook right thi exactli happen meth first thing struck oz wa brutal unflinch scene violenc set right word go trust thi show faint heart timid thi show pull punch regard drug sex violenc hardcor classic use wordit call oz nicknam given oswald maximum secur state penitentari focus mainli emerald citi experiment section prison cell glass front face inward privaci high agenda em citi home manyaryan muslim gangsta latino christian italian irish moreso scuffl death stare dodgi deal shadi agreement never far awayi would say main appeal show due fact goe show wouldnt dare forget pretti pictur paint mainstream audienc forget charm forget romanceoz doesnt mess around first episod ever saw struck nasti wa surreal couldnt say wa readi watch develop tast oz got accustom high level graphic violenc violenc injustic crook guard wholl sold nickel inmat wholl kill order get away well manner middl class inmat turn prison bitch due lack street skill prison experi watch oz may becom comfort uncomfort viewingthat get touch darker side'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#normalized train reviews\n",
    "norm_train_reviews=imdb_data.review[:4000]\n",
    "norm_train_reviews[0]\n",
    "#convert dataframe to string\n",
    "#norm_train_string=norm_train_reviews.to_string()\n",
    "#Spelling correction using Textblob\n",
    "#norm_train_spelling=TextBlob(norm_train_string)\n",
    "#norm_train_spelling.correct()\n",
    "#Tokenization using Textblob\n",
    "#norm_train_words=norm_train_spelling.words\n",
    "#norm_train_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "275609b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'love gorgeou greek sceneri stori someth follow anyway wa even harder follow movi cannot imagin anyon watch movi get ani kind grip read book like would probabl wonder whi australian allison turn french ann mani seemingli pointless chang stori mysteri book seem chop left movi saw first came problem sinc read book sever time recent watch granddaught veri intellig 20 usual movi like wa mostli amaz young michael cain candac bergen otherwis could imagin whi one would watch except sceneri'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Normalized test reviews\n",
    "norm_test_reviews=imdb_data.review[4000:]\n",
    "norm_test_reviews[4505]\n",
    "##convert dataframe to string\n",
    "#norm_test_string=norm_test_reviews.to_string()\n",
    "#spelling correction using Textblob\n",
    "#norm_test_spelling=TextBlob(norm_test_string)\n",
    "#print(norm_test_spelling.correct())\n",
    "#Tokenization using Textblob\n",
    "#norm_test_words=norm_test_spelling.words\n",
    "#norm_test_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "12c4fe8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW_cv_train: (4000, 793694)\n",
      "BOW_cv_test: (6000, 793694)\n"
     ]
    }
   ],
   "source": [
    "#Count vectorizer for bag of words\n",
    "cv=CountVectorizer(min_df=0,max_df=1,binary=False,ngram_range=(1,3))\n",
    "#transformed train reviews\n",
    "cv_train_reviews=cv.fit_transform(norm_train_reviews)\n",
    "#transformed test reviews\n",
    "cv_test_reviews=cv.transform(norm_test_reviews)\n",
    "\n",
    "print('BOW_cv_train:',cv_train_reviews.shape)\n",
    "print('BOW_cv_test:',cv_test_reviews.shape)\n",
    "#vocab=cv.get_feature_names()-toget feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cd97420c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tfidf_train: (4000, 793694)\n",
      "Tfidf_test: (6000, 793694)\n"
     ]
    }
   ],
   "source": [
    "#Tfidf vectorizer\n",
    "tv=TfidfVectorizer(min_df=0,max_df=1,use_idf=True,ngram_range=(1,3))\n",
    "#transformed train reviews\n",
    "tv_train_reviews=tv.fit_transform(norm_train_reviews)\n",
    "#transformed test reviews\n",
    "tv_test_reviews=tv.transform(norm_test_reviews)\n",
    "print('Tfidf_train:',tv_train_reviews.shape)\n",
    "print('Tfidf_test:',tv_test_reviews.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ba5b0d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "lb=LabelBinarizer()\n",
    "#transformed sentiment data\n",
    "sentiment_data=lb.fit_transform(imdb_data['sentiment'])\n",
    "print(sentiment_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ff9c32fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [1]]\n",
      "[[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "#Spliting the sentiment data\n",
    "train_sentiments=sentiment_data[:4000]\n",
    "test_sentiments=sentiment_data[4000:]\n",
    "print(train_sentiments)\n",
    "print(test_sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fb68b14c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sahithi\\appdata\\local\\programs\\python\\python39-32\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1, max_iter=500, random_state=42)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sahithi\\appdata\\local\\programs\\python\\python39-32\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1, max_iter=500, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "#training the model\n",
    "lr=LogisticRegression(penalty='l2',max_iter=500,C=1,random_state=42)\n",
    "#Fitting the model for Bag of words\n",
    "lr_bow=lr.fit(cv_train_reviews,train_sentiments)\n",
    "print(lr_bow)\n",
    "#Fitting the model for tfidf features\n",
    "lr_tfidf=lr.fit(tv_train_reviews,train_sentiments)\n",
    "print(lr_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "00541e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 ... 0 0 1]\n",
      "[0 1 1 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "#Predicting the model for bag of words\n",
    "lr_bow_predict=lr.predict(cv_test_reviews)\n",
    "print(lr_bow_predict)\n",
    "##Predicting the model for tfidf features\n",
    "lr_tfidf_predict=lr.predict(tv_test_reviews)\n",
    "print(lr_tfidf_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "afc593d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_bow_score : 0.6953333333333334\n",
      "lr_tfidf_score : 0.6573333333333333\n"
     ]
    }
   ],
   "source": [
    "#Accuracy score for bag of words\n",
    "lr_bow_score=accuracy_score(test_sentiments,lr_bow_predict)\n",
    "print(\"lr_bow_score :\",lr_bow_score)\n",
    "#Accuracy score for tfidf features\n",
    "lr_tfidf_score=accuracy_score(test_sentiments,lr_tfidf_predict)\n",
    "print(\"lr_tfidf_score :\",lr_tfidf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "377d5fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.66      0.78      0.71      2945\n",
      "    Negative       0.74      0.62      0.67      3055\n",
      "\n",
      "    accuracy                           0.70      6000\n",
      "   macro avg       0.70      0.70      0.69      6000\n",
      "weighted avg       0.70      0.70      0.69      6000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.60      0.90      0.72      2945\n",
      "    Negative       0.81      0.42      0.56      3055\n",
      "\n",
      "    accuracy                           0.66      6000\n",
      "   macro avg       0.71      0.66      0.64      6000\n",
      "weighted avg       0.71      0.66      0.64      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification report for bag of words \n",
    "lr_bow_report=classification_report(test_sentiments,lr_bow_predict,target_names=['Positive','Negative'])\n",
    "print(lr_bow_report)\n",
    "\n",
    "#Classification report for tfidf features\n",
    "lr_tfidf_report=classification_report(test_sentiments,lr_tfidf_predict,target_names=['Positive','Negative'])\n",
    "print(lr_tfidf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "27699817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1888 1167]\n",
      " [ 661 2284]]\n",
      "[[1295 1760]\n",
      " [ 296 2649]]\n"
     ]
    }
   ],
   "source": [
    "#confusion matrix for bag of words\n",
    "cm_bow=confusion_matrix(test_sentiments,lr_bow_predict,labels=[1,0])\n",
    "print(cm_bow)\n",
    "#confusion matrix for tfidf features\n",
    "cm_tfidf=confusion_matrix(test_sentiments,lr_tfidf_predict,labels=[1,0])\n",
    "print(cm_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ced353ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sahithi\\appdata\\local\\programs\\python\\python39-32\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\sahithi\\appdata\\local\\programs\\python\\python39-32\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB()\n",
      "MultinomialNB()\n"
     ]
    }
   ],
   "source": [
    "#training the model\n",
    "mnb=MultinomialNB()\n",
    "#fitting the svm for bag of words\n",
    "mnb_bow=mnb.fit(cv_train_reviews,train_sentiments)\n",
    "print(mnb_bow)\n",
    "#fitting the svm for tfidf features\n",
    "mnb_tfidf=mnb.fit(tv_train_reviews,train_sentiments)\n",
    "print(mnb_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5da6e085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 ... 0 0 1]\n",
      "[0 1 1 ... 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "#Predicting the model for bag of words\n",
    "mnb_bow_predict=mnb.predict(cv_test_reviews)\n",
    "print(mnb_bow_predict)\n",
    "#Predicting the model for tfidf features\n",
    "mnb_tfidf_predict=mnb.predict(tv_test_reviews)\n",
    "print(mnb_tfidf_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7da8db39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnb_bow_score : 0.7005\n",
      "mnb_tfidf_score : 0.691\n"
     ]
    }
   ],
   "source": [
    "#Accuracy score for bag of words\n",
    "mnb_bow_score=accuracy_score(test_sentiments,mnb_bow_predict)\n",
    "print(\"mnb_bow_score :\",mnb_bow_score)\n",
    "#Accuracy score for tfidf features\n",
    "mnb_tfidf_score=accuracy_score(test_sentiments,mnb_tfidf_predict)\n",
    "print(\"mnb_tfidf_score :\",mnb_tfidf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f07aff67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.68      0.74      0.71      2945\n",
      "    Negative       0.73      0.66      0.69      3055\n",
      "\n",
      "    accuracy                           0.70      6000\n",
      "   macro avg       0.70      0.70      0.70      6000\n",
      "weighted avg       0.70      0.70      0.70      6000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.65      0.81      0.72      2945\n",
      "    Negative       0.76      0.58      0.66      3055\n",
      "\n",
      "    accuracy                           0.69      6000\n",
      "   macro avg       0.70      0.69      0.69      6000\n",
      "weighted avg       0.70      0.69      0.69      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification report for bag of words \n",
    "mnb_bow_report=classification_report(test_sentiments,mnb_bow_predict,target_names=['Positive','Negative'])\n",
    "print(mnb_bow_report)\n",
    "#Classification report for tfidf features\n",
    "mnb_tfidf_report=classification_report(test_sentiments,mnb_tfidf_predict,target_names=['Positive','Negative'])\n",
    "print(mnb_tfidf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a0acd7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2024 1031]\n",
      " [ 766 2179]]\n",
      "[[1763 1292]\n",
      " [ 562 2383]]\n"
     ]
    }
   ],
   "source": [
    "#confusion matrix for bag of words\n",
    "cm_bow=confusion_matrix(test_sentiments,mnb_bow_predict,labels=[1,0])\n",
    "print(cm_bow)\n",
    "#confusion matrix for tfidf features\n",
    "cm_tfidf=confusion_matrix(test_sentiments,mnb_tfidf_predict,labels=[1,0])\n",
    "print(cm_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029e8f4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
